<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>武夫人</title>
  
  <subtitle>L.Wang Blogs</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-11-25T12:33:27.115Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>L.Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis事件机制</title>
    <link href="http://yoursite.com/2019/04/25/redisEvent1/"/>
    <id>http://yoursite.com/2019/04/25/redisEvent1/</id>
    <published>2019-04-25T14:05:23.000Z</published>
    <updated>2019-11-25T12:33:27.115Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Redis有两类事件：文件事件和时间事件，这两个事件组成了Redis的服务器的事件驱动程序。<a id="more"></a>  </p></blockquote><h3 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h3><p>Redis基于Reactor模式开发了自己的网络时间处理器：这个处理器被称为文件事件处理器。</p><p>文件事件处理器使用I/O多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的时间处理器。</p><p>当被监听的套接字准备好执行连结应答（accept）读取（read）写入（write）关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</p><p><img src="/2019/04/25/redisEvent1/FileEvent.png" alt="&#39;文件事件处理器的四个组成部分&#39;"></p><p>尽管多个文件事件可能会并发地出现，但I/O多路复用程序总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字。</p><p>文件事件分派器接受I/O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器。</p><h3 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h3><p>Redis的时间事件分为以下两类：</p><p>定时事件：让一段程序在指定的时间之后执行一次。<br>周期事件：让一段程序每隔指定时间就执行一次。</p><p>服务器将所有时间事件都放在一个无序链表中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。</p><p><img src="/2019/04/25/redisEvent1/Event.png" alt="事件处理角度下的服务器运行流程"></p><p>时间事件的运用实例：serverCron函数，它的主要工作包括：</p><ol><li>更新服务器的各类统计信息，比如：时间、内存占用、数据库占用情况等。</li><li>清理数据库中的过期键值对。</li><li>关闭清理连接失效的客户端。</li><li>尝试进行AOF或RDB之久化操作。</li><li>如果服务器是主服务器，对从服务器进行定期同步。</li><li>如果处于集群模式，对集群进行定期同步和连接测试。</li></ol><p>文件事件和时间事件是合作关系，服务器会轮流处理这两种事件，并且处理事件的过程中不会进行抢占。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Redis有两类事件：文件事件和时间事件，这两个事件组成了Redis的服务器的事件驱动程序。&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis持久化</title>
    <link href="http://yoursite.com/2018/11/25/redisback/"/>
    <id>http://yoursite.com/2018/11/25/redisback/</id>
    <published>2018-11-25T13:03:31.000Z</published>
    <updated>2019-11-27T05:56:50.528Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Redis的持久话方式分为AOF(Append Of File)和RDB两种方式。<a id="more"></a> </p></blockquote><h3 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h3><h4 id="RDB文件的创建与加载"><a href="#RDB文件的创建与加载" class="headerlink" title="RDB文件的创建与加载"></a>RDB文件的创建与加载</h4><p>&emsp;&emsp;有两个Redis命令可用于生成RDB文件，一个SAVE，另一个事BGSAVE。</p><p>&emsp;&emsp;SAVE命令会<font color="red">阻塞</font>Redis服务器进程。直到RDB文件创建完成为止，<font color="red">在服务器进程阻塞期间，服务器不能处理任何命令请求</font>。</p><p>&emsp;&emsp;BGSAVE命令会派生一个<font color="red">子进程</font>，然后由子进程负责创建RDB文件，<font color="red">服务器进行（父进程）继续处理命令请求</font>。</p><p>&emsp;&emsp;RDB文件的载入工作是在服务器启动时自动执行的，所以无论是SAVE、BGSAVE生成的RDB文件，载入的方式都是一致的。<font color="red">只要RDB服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。</font></p><p>&emsp;&emsp;因为AOF文件的更新频率通常比RDB文件的更新的频率高，所以:</p><ol><li>如果服务器开启了AOF持久化功能，那么服务器会优先使用AOF文件来还原数据库状态。</li><li>只有在AOF持久化功能处于关闭状态时，服务器才使用RDB文件来还原数据库状态。</li></ol><p>&emsp;&emsp;服务器禁止SAVE命令和BGSAVE命令同时执行是为了父进程（服务器进程）和子进程同时执行两个rdbSave调用，防止发生竞争。其次，在BGSAVE命令执行期间，客户端发送的BGSAVE命令会被服务器拒绝，因为同时执行两个BGSAVE也会产生竞争条件。</p><p>&emsp;&emsp;因为BGSAVE命令可以不阻塞服务器进程的情况下执行，所以Redis允许用户通过设置服务器配置的save选项，让服务器每个一段时间自动执行一次BGSAVE命令。</p><h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>AOF持久化的功能可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。</p><h4 id="AOF文件的创建"><a href="#AOF文件的创建" class="headerlink" title="AOF文件的创建"></a>AOF文件的创建</h4><h5 id="命令追加"><a href="#命令追加" class="headerlink" title="命令追加"></a>命令追加</h5><p>&emsp;&emsp;当AOF持久化功能处于打开状态时，服务器在执行完一个写入命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof buf缓冲区的末尾。</p><h5 id="AOF的文件写入"><a href="#AOF的文件写入" class="headerlink" title="AOF的文件写入"></a>AOF的文件写入</h5><p>&emsp;&emsp;Redis的服务器进程就是一个事件循环。因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里面，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到aof文件里面。</p><h5 id="AOF的文件同步"><a href="#AOF的文件同步" class="headerlink" title="AOF的文件同步"></a>AOF的文件同步</h5><p>&emsp;&emsp;为了提高文件的写入效率，在现代操作系统中，当用户调用writer函数，将一些数据写入到文件的时候，操作系统通常会将写入数据暂时保存在一个内存缓冲区里面，等到缓冲区的空间被填满，或者超过了指定的时限之后，才真正地将缓冲区中的数据写入到磁盘里面。</p><p>&emsp;&emsp;为此，系统提供了fsync和fdatasync两个同步函数，它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面，从而确保写入数据的安全性。</p><h4 id="AOF文件载入与数据还原"><a href="#AOF文件载入与数据还原" class="headerlink" title="AOF文件载入与数据还原"></a>AOF文件载入与数据还原</h4><p><img src="/2018/11/25/redisback/repository.png" alt="文件载入过程"></p><h4 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h4><p>&emsp;&emsp;为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写（rewrite）功能。通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比AOF文件的体积要小的多。</p><p>&emsp;&emsp;虽然Redis将生成新AOF文件替换旧AOF文件的功能命名为“AOF文件重写”，但实际上，AOF重写并不需要对现有的AOF文件进行任何读取、分析、或着写入操作，这个功能是通过读取服务器当前的数据库状态来实现的。</p><p>&emsp;&emsp;首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这就是AOF重写功能的实现。（<font color="red">先读后写</font>）</p><p><img src="/2018/11/25/redisback/aof01.png" alt="服务器同时将命令发送给AOF文件和AOF重写缓冲区"></p><p>&emsp;&emsp;Redis不希望AOF重写造成服务器无法处理请求，所以Redis决定将AOF重写程序放到子进程里执行，可以同时达到两个目的：</p><ol><li>子进程进行AOF重写期间，服务器进行（父进程）可以处理命令请求。</li><li>子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。</li></ol><h5 id="AOF重写过程中数据不一致的问题解决"><a href="#AOF重写过程中数据不一致的问题解决" class="headerlink" title="AOF重写过程中数据不一致的问题解决"></a>AOF重写过程中数据不一致的问题解决</h5><p>&emsp;&emsp;为了解决这种数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行了一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。</p><p>当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：</p><ol><li>将AOF重写缓冲区中的所有内容写入到新AOF文件汇总，这是新AOF文件所保存的数据库将和服务器当前的数据库状态一致。</li><li>对新的AOF文件进行改名，原子地覆盖现有的AOF文件，完成新旧两个AOF文件的替换。</li></ol><p>&emsp;&emsp;在整个AOF后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，其余时间，AOF后台重写都不会阻塞父进程。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Redis的持久话方式分为AOF(Append Of File)和RDB两种方式。&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ结构初识</title>
    <link href="http://yoursite.com/2018/07/28/rocketmq1/"/>
    <id>http://yoursite.com/2018/07/28/rocketmq1/</id>
    <published>2018-07-28T10:44:25.000Z</published>
    <updated>2019-11-28T11:09:00.126Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>要了解RocketMQ最好的方式就是查看源码，但是在看之前需要了解RocketMQ设计结构，并熟练使用它。所以就先了解结构<a id="more"></a></p></blockquote><p>&emsp;&emsp;Broker消息服务器在启动时间向所有NameServer注册，消息生产者（Producer）在发送消息之前<font color="red">先从NameServer获取Broker服务器地址列表</font>，然后根据<font color="red">负载算法</font>从列表中选择一台消息服务器进行消息发送。NameServer与每台Broker服务器保持<font color="red">长连接</font>，并间隔10s检测Broker是否存活，<font color="red">如果检测到Broker宕机，则从路由器中将其移除</font>。</p><p><img src="/2018/07/28/rocketmq1/rocketmq01.png" alt="RokcetMQ物理部署图"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;要了解RocketMQ最好的方式就是查看源码，但是在看之前需要了解RocketMQ设计结构，并熟练使用它。所以就先了解结构&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="RocketMQ" scheme="http://yoursite.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据对象初识</title>
    <link href="http://yoursite.com/2018/06/19/redisObjectInfo/"/>
    <id>http://yoursite.com/2018/06/19/redisObjectInfo/</id>
    <published>2018-06-19T09:31:43.000Z</published>
    <updated>2019-11-25T12:36:04.695Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>&emsp;&emsp;首先带着这几个问题：</p></blockquote><ol><li><p>redis有哪些对象？</p></li><li><p>redis对象底层的数据结构是什么？</p></li><li><p>为什么要选择这种数据结构？ <a id="more"></a></p></li></ol><h5 id="Redis对象"><a href="#Redis对象" class="headerlink" title="Redis对象"></a>Redis对象</h5><p>&emsp;&emsp;Redis每创建一个键值对时，至少会创建两个对象，一个对象用作键值对的键，一个用作键值对的值。每一个对象都由一个redisObject结构表示，结构中和保存数据有关的数据有三个属性分别是type属性、encoding属性和ptr属性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line">// 类型</span><br><span class="line">unsinged type:4;</span><br><span class="line">// 编码</span><br><span class="line">unsinged encoding:4;</span><br><span class="line">// 指向底层实现数据结构的指针</span><br><span class="line">void *ptr;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;Redis的对象有字符串（String），列表（List），集合（Set），哈希（Hash），有序集合（ZSet）这几种对象。</p><ul><li>字符串对象 </li></ul><ol><li>字符串对象的编码可以是int、raw或者embStr。 </li><li>对于int编码的字符串对象来说，如果我们执行了一些命令，使得这个对象保存的不再是整数值，而是一个字符串值，那么字符串对象的编码将从int变为raw。 </li><li>对embStr编码的字符串对象执行任何修改命令时，程序会先将对象的编码从embStr转换成raw，然后在执行命令。所以，embStr编码的字符串对象在执行修改命令之后，总会变成一个raw编码的字符串对象。 </li></ol><ul><li>列表对象 </li></ul><ol><li><p>列表对象的编码可以是ziplist或者linkedlist。 </p></li><li><p>ziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点保存一个列表元素。 </p></li><li><p>linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。 </p></li><li><p>编码转换 </p><p>&emsp;&emsp;当列表对象可以同时满足以下两个条件时，列表对象使用ziplist编码：列表对象保存的所有字符串元素的长度都小于64字节；列表对象保存的元素数量小于512个；不能满足这两个条件的列表对象需要使用linkedlist编码。 </p></li></ol><ul><li>哈希对象 </li></ul><ol><li><p>哈希对象的编码可以是ziplist或者hashtable。 </p></li><li><p>ziplist 编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的压缩列表节点推入到压缩列表表尾，所以保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；先添加到哈希对象中的键值对会放在压缩列表的表头方向，而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。 </p></li><li><p>hashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典值来保存：字典的每个键都是一个字符串对象，对象中保存了键值对的键。字典中的每一个值都是一个字符串对象，对象中保存了键值对的值。 </p></li><li><p>编码转换 </p><p>&emsp;&emsp;当哈希对象可以同时满足以下两个条件时，列表对象使用ziplist编码：哈希对象保存的所有字符串元素的长度都小于64字节；哈希对象保存的元素数量小于512个；不能满足这两个条件的哈希对象需要使用hashtable编码。 </p></li></ol><ul><li>集合对象 </li></ul><ol><li><p>集合对象的编码可以是inset或者hashtable。 </p></li><li><p>inset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面 </p></li><li><p>hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，字典的值则全部被设置为null。 </p></li><li><p>编码的转换 </p><p>&emsp;&emsp;当集合对象可以同时满足以下两个条件时，对象使用insert编码：集合对象保存的所有元素都是整数值,集合对象保存的元素数量小于512个；不能满足这两个条件的哈希对象需要使用hashtable编码。 </p></li></ol><ul><li><p>有序集合对象 </p><p>&emsp;&emsp;有序集合的编码可以是ziplist或者skiplist。 </p><ol><li><p>ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的位置，而分值较大的元素则被放置在靠近表尾的位置。 </p></li><li><p>skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表。zset结构中的zs1跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的object属性保存了元素的成员，而跳跃表节点的score属性则保存了元素的分值。 </p></li><li><p>编码转换 </p><p>&emsp;&emsp;当有序集合对象可以同时满足以下两个条件时，对象可以使用ziplist编码：有序集合对象保存的元素数量小于128个；有序集合对象保存的所有元素成员的长度都小于64字节；不能满足这两个条件的列表对象需要使用skiplist编码。 </p><p><img src="/2018/06/19/redisObjectInfo/redis对象.png" alt="&#39;Redis对象&#39;"></p></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&amp;emsp;&amp;emsp;首先带着这几个问题：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;redis有哪些对象？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;redis对象底层的数据结构是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为什么要选择这种数据结构？&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>JVM垃圾收集（一）</title>
    <link href="http://yoursite.com/2018/04/29/gc01/"/>
    <id>http://yoursite.com/2018/04/29/gc01/</id>
    <published>2018-04-29T10:12:02.000Z</published>
    <updated>2019-11-25T12:36:04.694Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>&emsp;&emsp;在JVM中,进行垃圾回收首先要判断对象对象是否存活，在对不同生命周期的对象进行垃圾回收。在进行垃圾回收时，要根据需求进行垃圾回收算法的选择。（比如注重吞吐量）<a id="more"></a>  </p></blockquote><h5 id="如何判断对象存活"><a href="#如何判断对象存活" class="headerlink" title="如何判断对象存活"></a>如何判断对象存活</h5><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">思想</th><th style="text-align:center">优缺点</th></tr></thead><tbody><tr><td style="text-align:center">引用计数算法</td><td style="text-align:center">给对象一个计数器，有人引用就加1,引用失效就减1。当计数器为0时，则对象不再被引用。</td><td style="text-align:center">优点：实现简单，判定效率高。缺点：很难解决对象之间相互循环调用的问题</td></tr><tr><td style="text-align:center">可达性分析算法</td><td style="text-align:center">以GC Roots为起点，当一个对象没有以GC Roots为起点的引用链时，则对象不再被引用</td><td style="text-align:center"></td></tr></tbody></table><p>在jdk中引用分为强引用、软引用、弱引用、虚引用。  </p><table><thead><tr><th style="text-align:center">强引用</th><th style="text-align:center">软引用</th><th style="text-align:center">弱引用</th><th style="text-align:center">虚引用</th></tr></thead><tbody><tr><td style="text-align:center">强引用只要存在，就不会被回收</td><td style="text-align:center">在系统将要发生内存溢出时，对象将进入二次垃圾回收范围</td><td style="text-align:center">只能生存到下一次垃圾回收之前</td><td style="text-align:center">惟一的目的就是能在这个对像被收集器回收时收到一个系统的通知</td></tr></tbody></table><h5 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h5><blockquote><p>&emsp;&emsp;在JVM中，可以把堆分为1/3的新生代和2/3的老生代。在将新生代按照8:2分为Eden区和Survivor区。而在Survivor区有按照1:1分为两个，记为from，to区。(各参数依据默认参数)<br><img src="/2018/04/29/gc01/heap.png" alt="&#39;堆的内存结构&#39;"><br>在新创建一个对象时，首先要对一个对象进行判断，是大对象还是一般的对象（需要占用连续的内存空间：如较长的字符串数组）。如果是大对象就会直接进入老年代，否则一般的对象都会进入Eden区。如下图所示：<br><img src="/2018/04/29/gc01/newObj.png" alt="&#39;对象建立的过程&#39;"><br>而对于垃圾收集器的选择具体如下图所示：<br><img src="/2018/04/29/gc01/gccollector.png" alt="&#39;垃圾收集器的组合&#39;"><br>我们需要针对不同的场合选择垃圾收集器。  </p></blockquote><table><thead><tr><th style="text-align:center">Serial</th><th style="text-align:center">ParNew</th><th style="text-align:center">Parallel Scavenge</th><th style="text-align:center">Serial Old</th><th style="text-align:center">Parallel Old</th></tr></thead><tbody><tr><td style="text-align:center">单线程的收集器，只会使用一个CPU或一条收集器去完成垃圾收集工作，并在在它进行垃圾收集时，必须暂停其他所有工作的线程</td><td style="text-align:center">Serial收集器的多线程版本，也同样要暂停其他工作线程。只有它能与CMS收集器配合。</td><td style="text-align:center">CMS等收集器注重缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge是达到一个可控制的吞吐量。主要适合在后台运算而不需要太多交互的任务</td><td style="text-align:center">单线程收集器，使用标记-整理算法。主要用来和JDK1.5及以前的版本中与Parallel Scavenge配合使用和作为CMS收集器的后备预案，在并发收集器发生Concurrent Mode Failure时使用</td><td style="text-align:center">使用了多线程和标记-整理算法，在注重吞吐量以及CPU资源敏感的场合优先考虑Parallel Scavenge和Parallel Old收集器</td></tr></tbody></table><ul><li>CMS(Currernt Mark Sweep)<br>CMS收集器采用“标记-清除”算法，从而达到以获取最短回收停顿时间的目标。它分为4个步骤：  <ul><li>初始标记<br>标记GC Roots能直接关联到的对象，速度很快。</li><li>并发标记<br>进行GC Roots Tracing的过程。</li><li>重新标记<br>为了修正并发标记时间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，</li><li>并发清除<br>并发清除GC Roots不可达的对象。<br>优点：并发收集，低停顿。<br>缺点：1、CMS收集线对CPU资源非常敏感。<br>&emsp;&emsp;&emsp;2、CMS收集器无法处理浮动的垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。当出现Concurrent Mode Failure失败时，虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，停顿的时间会加长。<br>&emsp;&emsp;&emsp;3、“标记-清除”会产生大量的空间碎片。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&amp;emsp;&amp;emsp;在JVM中,进行垃圾回收首先要判断对象对象是否存活，在对不同生命周期的对象进行垃圾回收。在进行垃圾回收时，要根据需求进行垃圾回收算法的选择。（比如注重吞吐量）&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
      <category term="JVM" scheme="http://yoursite.com/categories/JVM/"/>
    
    
      <category term="CMS" scheme="http://yoursite.com/tags/CMS/"/>
    
      <category term="Serial" scheme="http://yoursite.com/tags/Serial/"/>
    
      <category term="ParNew" scheme="http://yoursite.com/tags/ParNew/"/>
    
      <category term="Parallel" scheme="http://yoursite.com/tags/Parallel/"/>
    
      <category term="Scavenge" scheme="http://yoursite.com/tags/Scavenge/"/>
    
      <category term="Serial Old" scheme="http://yoursite.com/tags/Serial-Old/"/>
    
      <category term="Parallel Old" scheme="http://yoursite.com/tags/Parallel-Old/"/>
    
      <category term="G1" scheme="http://yoursite.com/tags/G1/"/>
    
  </entry>
  
</feed>
